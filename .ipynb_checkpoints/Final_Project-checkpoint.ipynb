{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "developmental-scottish",
   "metadata": {},
   "source": [
    "# Caruana Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "choice-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-corner",
   "metadata": {},
   "source": [
    "## Define Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-patch",
   "metadata": {},
   "source": [
    "### Algorithm 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grave-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(X_train, X_test, y_train, y_test):\n",
    "    # Logistic Regression binary classification\n",
    "    C_list = [1e-4, 1e-3, 1e-2, 1e-1,1e0, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8]\n",
    "    scoring = ['accuracy', 'f1', 'roc_auc']\n",
    "    param_grid = [{'classifier__C': C_list, 'classifier__penalty': ['l2']}, \n",
    "                  {'classifier__C': [None], 'classifier__penalty': ['none']}]\n",
    "    pipe = Pipeline([('std', StandardScaler()),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "    clf = GridSearchCV(pipe, param_grid, return_train_score = True, \n",
    "                       n_jobs = -1, scoring = scoring, refit = False, cv=StratifiedKFold(n_splits=5))\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    results = clf.cv_results_\n",
    "    \n",
    "    # Find best parameters and optimal for each performance metric\n",
    "    best_C_acc = clf.cv_results_['params'][np.argmin(results['rank_test_accuracy'])]['classifier__C']\n",
    "    best_penalty_acc = clf.cv_results_['params'][np.argmin(results['rank_test_accuracy'])]['classifier__penalty']\n",
    "    \n",
    "    best_C_f1 = clf.cv_results_['params'][np.argmin(results['rank_test_f1'])]['classifier__C']\n",
    "    best_penalty_f1 = clf.cv_results_['params'][np.argmin(results['rank_test_f1'])]['classifier__penalty']\n",
    "\n",
    "    best_C_roc = clf.cv_results_['params'][np.argmin(results['rank_test_roc_auc'])]['classifier__C']\n",
    "    best_penalty_roc = clf.cv_results_['params'][np.argmin(results['rank_test_roc_auc'])]['classifier__penalty']\n",
    "\n",
    "    print(\"Found Best Parameters!\")\n",
    "    \n",
    "    # Train 3 models using the 5000 samples and each of the 3 best parameter settings (one model per metric)\n",
    "    best_model_acc = LogisticRegression(C=best_C_acc, n_jobs = -1, penalty=best_penalty_acc)\n",
    "    best_model_f1 = LogisticRegression(C=best_C_f1, n_jobs = -1, penalty = best_penalty_f1)\n",
    "    best_model_roc = LogisticRegression(C=best_C_roc, n_jobs = -1, penalty = best_penalty_roc)\n",
    "    best_model_acc.fit(X_train, y_train)\n",
    "    best_model_f1.fit(X_train, y_train)\n",
    "    best_model_roc.fit(X_train, y_train)\n",
    "    \n",
    "    # Find and store accuracy, FSC, and AUC of the 3 models from previous line on test set\n",
    "    y_pred1 = best_model_acc.predict(X_test)\n",
    "    y_pred2 = best_model_f1.predict(X_test)\n",
    "    y_pred3 = best_model_roc.predict(X_test)\n",
    "    \n",
    "    metrics_acc = accuracy_score(y_test, y_pred1)\n",
    "    metrics_f1 = f1_score(y_test, y_pred2)\n",
    "    metrics_auc = roc_auc_score(y_test, y_pred3)\n",
    "    \n",
    "    return metrics_acc, metrics_f1, metrics_auc, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-dominant",
   "metadata": {},
   "source": [
    "### Algorithm 2: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dying-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train, X_test, y_train, y_test):\n",
    "    # KNN binary classification\n",
    "    k_list = [i for i in range(1,106,4)]\n",
    "    weights = ['uniform', 'distance']\n",
    "    param_grid = [{'classifier__n_neighbors': k_list, 'classifier__weights': weights}]\n",
    "    scoring = ['accuracy', 'f1', 'roc_auc']\n",
    "    pipe = Pipeline([('classifier', KNeighborsClassifier())])\n",
    "    clf = GridSearchCV(pipe, param_grid, return_train_score = True, \n",
    "                       n_jobs = -1, scoring = scoring, refit = False, cv=StratifiedKFold(n_splits=5))\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    results = clf.cv_results_\n",
    "    \n",
    "    # Find best parameters for each performance metric\n",
    "    best_k_acc = results['params'][np.argmin(results['rank_test_accuracy'])]['classifier__n_neighbors']\n",
    "    best_weight_acc = results['params'][np.argmin(results['rank_test_accuracy'])]['classifier__weights']\n",
    "    \n",
    "    best_k_f1 = results['params'][np.argmin(results['rank_test_f1'])]['classifier__n_neighbors']\n",
    "    best_weight_f1 = results['params'][np.argmin(results['rank_test_f1'])]['classifier__weights']\n",
    "    \n",
    "    best_k_roc = results['params'][np.argmin(results['rank_test_roc_auc'])]['classifier__n_neighbors']\n",
    "    best_weight_roc = results['params'][np.argmin(results['rank_test_roc_auc'])]['classifier__weights']\n",
    "    \n",
    "    print(\"Found Best Parameters!\") \n",
    "    \n",
    "    # Train 3 models using the 5000 samples and each of the 3 best parameter settings (one model per metric)\n",
    "    best_model_acc = KNeighborsClassifier(n_neighbors = best_k_acc, weights = best_weight_acc)\n",
    "    best_model_f1 = KNeighborsClassifier(n_neighbors = best_k_f1, weights = best_weight_f1)\n",
    "    best_model_roc = KNeighborsClassifier(n_neighbors = best_k_roc, weights = best_weight_roc)\n",
    "    best_model_acc.fit(X_train, y_train)\n",
    "    best_model_f1.fit(X_train, y_train)\n",
    "    best_model_roc.fit(X_train, y_train)\n",
    "    \n",
    "    # Find and store accuracy, FSC, and AUC of the 3 models from previous line on test set\n",
    "    y_pred1 = best_model_acc.predict(X_test)\n",
    "    y_pred2 = best_model_f1.predict(X_test)\n",
    "    y_pred3 = best_model_roc.predict(X_test)\n",
    "    \n",
    "    metrics_acc = accuracy_score(y_test, y_pred1)\n",
    "    metrics_f1 = f1_score(y_test, y_pred2)\n",
    "    metrics_auc = roc_auc_score(y_test, y_pred3)\n",
    "    return metrics_acc, metrics_f1, metrics_auc, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-lodging",
   "metadata": {},
   "source": [
    "### Algorithm 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sealed-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_for(X_train, X_test, y_train, y_test):\n",
    "    # Random Forest binary classification\n",
    "    feat_list = [1, 2, 4, 6, 8, 12, 16, 20]\n",
    "    n_trees = [1024]\n",
    "    scoring = ['accuracy', 'f1', 'roc_auc']\n",
    "    param_grid = {'classifier__n_estimators': n_trees, 'classifier__max_features': feat_list}\n",
    "    pipe = Pipeline([('std', StandardScaler()),\n",
    "                 ('classifier', RandomForestClassifier())])\n",
    "    clf = GridSearchCV(pipe, param_grid, return_train_score = True, \n",
    "                       n_jobs = -1, scoring = scoring, refit = False, cv=StratifiedKFold(n_splits=5))\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    results = clf.cv_results_\n",
    "    \n",
    "    # Find best parameters for each performance metric\n",
    "    best_est_acc = results['params'][np.argmin(results['rank_test_accuracy'])]['classifier__n_estimators']\n",
    "    best_feat_acc = results['params'][np.argmin(results['rank_test_accuracy'])]['classifier__max_features']\n",
    "    \n",
    "    best_est_f1 = results['params'][np.argmin(results['rank_test_f1'])]['classifier__n_estimators']\n",
    "    best_feat_f1 = results['params'][np.argmin(results['rank_test_f1'])]['classifier__max_features']\n",
    "    \n",
    "    best_est_roc = results['params'][np.argmin(results['rank_test_roc_auc'])]['classifier__n_estimators']\n",
    "    best_feat_roc = results['params'][np.argmin(results['rank_test_roc_auc'])]['classifier__max_features']\n",
    "            \n",
    "    print(\"Found Best Parameters!\")\n",
    "    \n",
    "    # Train 3 models using the 5000 samples and each of the 3 best parameter settings (one model per metric)\n",
    "    best_model_acc = RandomForestClassifier(n_estimators=best_est_acc, n_jobs = -1, max_features = best_feat_acc)\n",
    "    best_model_f1 = RandomForestClassifier(n_estimators=best_est_f1, n_jobs = -1, max_features = best_feat_f1)\n",
    "    best_model_auc = RandomForestClassifier(n_estimators=best_est_roc, n_jobs = -1, max_features = best_feat_roc)\n",
    "    best_model_acc.fit(X_train, y_train)\n",
    "    best_model_f1.fit(X_train, y_train)\n",
    "    best_model_auc.fit(X_train, y_train)\n",
    "    \n",
    "    # Find and store accuracy, FSC, and AUC of the 3 models from previous line on test set\n",
    "    y_pred1 = best_model_acc.predict(X_test)\n",
    "    y_pred2 = best_model_f1.predict(X_test)\n",
    "    y_pred3 = best_model_auc.predict(X_test)\n",
    "    \n",
    "    metrics_acc = accuracy_score(y_test, y_pred1)\n",
    "    metrics_f1 = f1_score(y_test, y_pred2)\n",
    "    metrics_auc = roc_auc_score(y_test, y_pred3)\n",
    "    return metrics_acc, metrics_f1, metrics_auc, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wooden-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_heatmap(training_accuracy, C_list, label):\n",
    "    # training_accuracy: A NumPy array with the shape (len(C_list))\n",
    "    # C_list: List of C(s).\n",
    "    plt.figure(figsize = (2,4))\n",
    "    ax = sns.heatmap(training_accuracy, annot=True, fmt='.3f', \n",
    "                     xticklabels=[], yticklabels=C_list)\n",
    "    ax.collections[0].colorbar.set_label(\"accuracy\")\n",
    "    ax.set(ylabel='$C$')\n",
    "    sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "    plt.title(label + 'accuracy w.r.t $C$')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-samoa",
   "metadata": {},
   "source": [
    "## Adult Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-plane",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "material-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = ['age', 'workclass', 'fnlwgt','education', 'education-num', 'marital-status', \n",
    "        'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "        'hours-per-week', 'native-country', 'class']\n",
    "features = ['age', 'workclass', 'fnlwgt','education', 'education-num', 'marital-status', \n",
    "        'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "        'hours-per-week', 'native-country']\n",
    "data1_1 = pd.read_csv('./ADULT/adult.data', header = None, names = cols1)\n",
    "data1_2 = pd.read_csv('./ADULT/adult.test', header = None, names = cols1)\n",
    "frames = [data1_1, data1_2]\n",
    "data1 = pd.concat(frames)\n",
    "data1 = data1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "forced-likelihood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48843, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-maintenance",
   "metadata": {},
   "source": [
    "### Clean and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charming-timing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index               int64\n",
      "age                object\n",
      "workclass          object\n",
      "fnlwgt            float64\n",
      "education          object\n",
      "education-num     float64\n",
      "marital-status     object\n",
      "occupation         object\n",
      "relationship       object\n",
      "race               object\n",
      "sex                object\n",
      "capital-gain      float64\n",
      "capital-loss      float64\n",
      "hours-per-week    float64\n",
      "native-country     object\n",
      "class              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Types in each column\n",
    "print(data1.dtypes)\n",
    "\n",
    "# Drop any nulls, shown as question marks\n",
    "for i in range(len(data1)):\n",
    "    for col in cols1:\n",
    "        if data1[col][i] == ' ?':\n",
    "            data1.drop(i, inplace = True)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "matched-smart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45223, 16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "renewable-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess last column\n",
    "def transform_income(income):\n",
    "    if income == ' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "convenient-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['class'] = data1['class'].apply(transform_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cellular-auction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>160187.0</td>\n",
       "      <td>9th</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>209642.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>45781.0</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14084.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>159449.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index age          workclass    fnlwgt   education  education-num  \\\n",
       "0      0  39          State-gov   77516.0   Bachelors           13.0   \n",
       "1      1  50   Self-emp-not-inc   83311.0   Bachelors           13.0   \n",
       "2      2  38            Private  215646.0     HS-grad            9.0   \n",
       "3      3  53            Private  234721.0        11th            7.0   \n",
       "4      4  28            Private  338409.0   Bachelors           13.0   \n",
       "5      5  37            Private  284582.0     Masters           14.0   \n",
       "6      6  49            Private  160187.0         9th            5.0   \n",
       "7      7  52   Self-emp-not-inc  209642.0     HS-grad            9.0   \n",
       "8      8  31            Private   45781.0     Masters           14.0   \n",
       "9      9  42            Private  159449.0   Bachelors           13.0   \n",
       "\n",
       "           marital-status          occupation    relationship    race  \\\n",
       "0           Never-married        Adm-clerical   Not-in-family   White   \n",
       "1      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3      Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4      Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "5      Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "6   Married-spouse-absent       Other-service   Not-in-family   Black   \n",
       "7      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "8           Never-married      Prof-specialty   Not-in-family   White   \n",
       "9      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country  class  \n",
       "0     Male        2174.0           0.0            40.0   United-States      0  \n",
       "1     Male           0.0           0.0            13.0   United-States      0  \n",
       "2     Male           0.0           0.0            40.0   United-States      0  \n",
       "3     Male           0.0           0.0            40.0   United-States      0  \n",
       "4   Female           0.0           0.0            40.0            Cuba      0  \n",
       "5   Female           0.0           0.0            40.0   United-States      0  \n",
       "6   Female           0.0           0.0            16.0         Jamaica      0  \n",
       "7     Male           0.0           0.0            45.0   United-States      1  \n",
       "8   Female       14084.0           0.0            50.0   United-States      1  \n",
       "9     Male        5178.0           0.0            40.0   United-States      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compound-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "federal-mirror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45222, 16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ruled-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data1[features]\n",
    "y1 = data1['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unavailable-motor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age          workclass    fnlwgt   education  education-num  \\\n",
       "0  39          State-gov   77516.0   Bachelors           13.0   \n",
       "1  50   Self-emp-not-inc   83311.0   Bachelors           13.0   \n",
       "2  38            Private  215646.0     HS-grad            9.0   \n",
       "3  53            Private  234721.0        11th            7.0   \n",
       "4  28            Private  338409.0   Bachelors           13.0   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0        2174.0           0.0            40.0   United-States  \n",
       "1           0.0           0.0            13.0   United-States  \n",
       "2           0.0           0.0            40.0   United-States  \n",
       "3           0.0           0.0            40.0   United-States  \n",
       "4           0.0           0.0            40.0            Cuba  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lucky-celebrity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'education-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "biblical-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.get_dummies(X1, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race',\n",
    " 'sex','native-country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "upper-physics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                                 object\n",
      "fnlwgt                             float64\n",
      "education-num                      float64\n",
      "capital-gain                       float64\n",
      "capital-loss                       float64\n",
      "                                    ...   \n",
      "native-country_ Thailand             uint8\n",
      "native-country_ Trinadad&Tobago      uint8\n",
      "native-country_ United-States        uint8\n",
      "native-country_ Vietnam              uint8\n",
      "native-country_ Yugoslavia           uint8\n",
      "Length: 104, dtype: object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# Types in each column\n",
    "print(X1.dtypes)\n",
    "print(y1.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ruled-event",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45222, 104)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "objective-mumbai",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45222,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-philippines",
   "metadata": {},
   "source": [
    "### Classification: Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-bunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.6476 0.6496 0.6528 0.6498 0.6488 0.6486 0.6486 0.6486 0.6486 0.6486\n",
      " 0.6486 0.6486 0.6486    nan]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the train scores are non-finite: [0.6551  0.66035 0.66385 0.66665 0.6659  0.66605 0.66605 0.66605 0.66605\n",
      " 0.66605 0.66605 0.66605 0.66605     nan]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.65188341 0.65316092 0.65456697 0.64885987 0.6466228  0.64634399\n",
      " 0.64634399 0.64634399 0.64634399 0.64634399 0.64634399 0.64634399\n",
      " 0.64634399        nan]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the train scores are non-finite: [0.65864935 0.66262909 0.66399318 0.66396378 0.66189528 0.66172058\n",
      " 0.66172058 0.66172058 0.66168604 0.66168604 0.66168604 0.66168604\n",
      " 0.66168604        nan]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.69861829 0.69919431 0.69728065 0.69757667 0.69679265 0.69665824\n",
      " 0.69665024 0.69663264 0.69664624 0.69664224 0.69664224 0.69664304\n",
      " 0.69664304        nan]\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the train scores are non-finite: [0.70833379 0.71706426 0.72200182 0.72382473 0.72361177 0.72352767\n",
      " 0.72351942 0.72351732 0.72351882 0.72351882 0.72351897 0.72351942\n",
      " 0.72351947        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Best Parameters!\n",
      "Found Best Parameters!\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LRD1 = np.zeros((5, 3))\n",
    "KNND1 = np.zeros((5, 3))\n",
    "RDF1 = np.zeros((5, 3))\n",
    "for trial in range(5):\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, train_size = 5000)\n",
    "    metrics_acc_log, metrics_f1_log, metrics_auc_log, results_log_d1 = log_reg(X1_train, X1_test, y1_train, y1_test)\n",
    "    metrics_acc_knn, metrics_f1_knn, metrics_auc_knn, results_knn_d1 = knn(X1_train, X1_test, y1_train, y1_test)\n",
    "    metrics_acc_rf, metrics_f1_rf, metrics_auc_rf, results_rf_d1 = rand_for(X1_train, X1_test, y1_train, y1_test)\n",
    "    LRD1[trial][0] = metrics_acc_log\n",
    "    LRD1[trial][1] = metrics_f1_log\n",
    "    LRD1[trial][2] = metrics_auc_log\n",
    "    KNND1[trial][0] = metrics_acc_knn\n",
    "    KNND1[trial][1] = metrics_f1_knn\n",
    "    KNND1[trial][2] = metrics_auc_knn\n",
    "    RDF1[trial][0] = metrics_acc_rf\n",
    "    RDF1[trial][1] = metrics_f1_rf\n",
    "    RDF1[trial][2] = metrics_auc_rf\n",
    "LRD1 = pd.DataFrame(LRD1, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "KNND1 = pd.DataFrame(KNND1, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "RDF1 = pd.DataFrame(RDF1, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "\n",
    "AD1 = [[LRD1], [KNND1], [RDF1]]\n",
    "AD1 = pd.DataFrame(AD1, columns = ['ADULT'], index = ['LR', 'KNN', 'RAND_FOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNND1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-citation",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-helmet",
   "metadata": {},
   "source": [
    "## Cover Type Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-current",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2 = ['elevation', 'aspect', 'slope', 'horizontal_distance_to_hydrology', 'vertical_distance_to_hydrology',\n",
    "       'horizontal_distance_to_roadways', 'hillshade_9am', 'hillshade_noon', 'hillshade_3pm', \n",
    "       'horizontal_distance_to_fire_points', 'wilderness_area1', 'wilderness_area2','wilderness_area3','wilderness_area4',\n",
    "        'soil_type1','soil_type2','soil_type3','soil_type4','soil_type5','soil_type6','soil_type7','soil_type8',\n",
    "        'soil_type9','soil_type10','soil_type11','soil_type12','soil_type13','soil_type14','soil_type15','soil_type16','soil_type17',\n",
    "        'soil_type18', 'soil_type19', 'soil_type20', 'soil_type21', 'soil_type22', 'soil_type23', 'soil_type24', 'soil_type25', 'soil_type26',\n",
    "        'soil_type27', 'soil_type28', 'soil_type29', 'soil_type30', 'soil_type31', 'soil_type32', 'soil_type33', 'soil_type34', 'soil_type35', \n",
    "        'soil_type36', 'soil_type37', 'soil_type38', 'soil_type39', 'soil_type40', 'cover_type']\n",
    "data2 = pd.read_csv('./COVTYPE/covtype.data', header = None, names = cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-photography",
   "metadata": {},
   "source": [
    "### Clean and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types in each column\n",
    "print(data2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any null variables\n",
    "data2.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method in Caruana Paper: Largest class(7) is positive and everything else is negative\n",
    "def transform_type(covtype):\n",
    "    if covtype == 7:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['cover_type'] = data2['cover_type'].apply(transform_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only picked a subset of dataset to match size in Caruana paper\n",
    "X2 = data2.iloc[:30000, :-1]\n",
    "y2 = data2.iloc[:30000, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-navigator",
   "metadata": {},
   "source": [
    "### Classification: Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "LRD2 = np.zeros((5, 3))\n",
    "KNND2 = np.zeros((5, 3))\n",
    "RDF2 = np.zeros((5, 3))\n",
    "for trial in range(5):\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, train_size = 5000)\n",
    "    metrics_acc_log, metrics_f1_log, metrics_auc_log, results_log_d2 = log_reg(X2_train, X2_test, y2_train, y2_test)\n",
    "    metrics_acc_knn, metrics_f1_knn, metrics_auc_knn, results_knn_d2 = knn(X2_train, X2_test, y2_train, y2_test)\n",
    "    metrics_acc_rf, metrics_f1_rf, metrics_auc_rf, results_rf_d2 = rand_for(X2_train, X2_test, y2_train, y2_test)\n",
    "    LRD2[trial][0] = metrics_acc_log\n",
    "    LRD2[trial][1] = metrics_f1_log\n",
    "    LRD2[trial][2] = metrics_auc_log\n",
    "    KNND2[trial][0] = metrics_acc_knn\n",
    "    KNND2[trial][1] = metrics_f1_knn\n",
    "    KNND2[trial][2] = metrics_auc_knn\n",
    "    RDF2[trial][0] = metrics_acc_rf\n",
    "    RDF2[trial][1] = metrics_f1_rf\n",
    "    RDF2[trial][2] = metrics_auc_rf\n",
    "LRD2 = pd.DataFrame(LRD2, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "KNND2 = pd.DataFrame(KNND2, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "RDF2 = pd.DataFrame(RDF2, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "\n",
    "AD2 = [[LRD2], [KNND2], [RDF2]]\n",
    "AD2 = pd.DataFrame(AD2, columns = ['COVTYPE'], index = ['LR', 'KNN', 'RAND_FOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNND2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-sperm",
   "metadata": {},
   "source": [
    "## Letter Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-tattoo",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols3 = ['lettr', 'x-box', 'y-box', 'width', 'high', 'onpix', 'x-bar', \n",
    "         'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy',\n",
    "        'y-ege', 'yegvx']\n",
    "data3 = pd.read_csv('./LETTER/letter-recognition.data', header = None, names = cols3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-investor",
   "metadata": {},
   "source": [
    "### Clean and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types in each column\n",
    "print(data3.dtypes)\n",
    "\n",
    "# Check if there are any null variables\n",
    "data3.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method in Caruana Paper: A-M is positive and everything else is negative\n",
    "def transform_letter(letter):\n",
    "    positive = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M']\n",
    "    if letter in positive:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3['lettr'] = data3['lettr'].apply(transform_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = data3.iloc[:, 1:]\n",
    "y3 = data3.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = X3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-consumer",
   "metadata": {},
   "source": [
    "### Classification: Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "LRD3 = np.zeros((5, 3))\n",
    "KNND3 = np.zeros((5, 3))\n",
    "RDF3 = np.zeros((5, 3))\n",
    "for trial in range(5):\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, train_size = 5000)\n",
    "    metrics_acc_log, metrics_f1_log, metrics_auc_log, results_log_d3 = log_reg(X3_train, X3_test, y3_train, y3_test)\n",
    "    metrics_acc_knn, metrics_f1_knn, metrics_auc_knn, results_knn_d3 = knn(X3_train, X3_test, y3_train, y3_test)\n",
    "    metrics_acc_rf, metrics_f1_rf, metrics_auc_rf, results_rf_d3 = rand_for(X3_train, X3_test, y3_train, y3_test)\n",
    "    LRD3[trial][0] = metrics_acc_log\n",
    "    LRD3[trial][1] = metrics_f1_log\n",
    "    LRD3[trial][2] = metrics_auc_log\n",
    "    KNND3[trial][0] = metrics_acc_knn\n",
    "    KNND3[trial][1] = metrics_f1_knn\n",
    "    KNND3[trial][2] = metrics_auc_knn\n",
    "    RDF3[trial][0] = metrics_acc_rf\n",
    "    RDF3[trial][1] = metrics_f1_rf\n",
    "    RDF3[trial][2] = metrics_auc_rf\n",
    "LRD3 = pd.DataFrame(LRD3, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "KNND3 = pd.DataFrame(KNND3, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "RDF3 = pd.DataFrame(RDF3, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "\n",
    "AD3 = [[LRD3], [KNND3], [RDF3]]\n",
    "AD3 = pd.DataFrame(AD3, columns = ['LETTER'], index = ['LR', 'KNN', 'RAND_FOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNND3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-thought",
   "metadata": {},
   "source": [
    "## MUSH Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spread-mother",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols4 = ['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', \n",
    "         'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', \n",
    "        'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', \n",
    "        'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', \n",
    "        'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', \n",
    "        'habitat']\n",
    "new_cols = ['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', \n",
    "         'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', \n",
    "            'stalk-surface-above-ring', 'stalk-surface-below-ring', \n",
    "        'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', \n",
    "        'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', \n",
    "        'habitat']\n",
    "data4 = pd.read_csv('./MUSH/mushroom.data', header = None, names = cols4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-neighbor",
   "metadata": {},
   "source": [
    "### Clean and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find null value in dataframe\n",
    "data4['stalk-root'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many rows with nulls are in dataset\n",
    "null_rows = 0\n",
    "for i in range(len(data4)):\n",
    "    for col in cols4:\n",
    "        if data4[col][i] == '?':\n",
    "            null_rows += 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-lancaster",
   "metadata": {},
   "source": [
    "There are a significant number of nulls in the dataset, so instead of dropping the instances, we can note that the nulls are all in column 11, so we can drop a feature, since we have a large amount of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = data4.drop(['stalk-root'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check nulls again\n",
    "null_rows = 0\n",
    "for i in range(len(data4)):\n",
    "    for col in new_cols:\n",
    "        if data4[col][i] == '?':\n",
    "            null_rows += 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = pd.get_dummies(data4, columns=['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
    "       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
    "       'stalk-shape', 'stalk-surface-above-ring', 'stalk-surface-below-ring',\n",
    "       'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type',\n",
    "       'veil-color', 'ring-number', 'ring-type', 'spore-print-color',\n",
    "       'population', 'habitat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_class(mushroom):\n",
    "    if mushroom == 'e':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4['class'] = data4['class'].apply(transform_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = data4.iloc[:, 1:]\n",
    "y4 = data4.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-music",
   "metadata": {},
   "source": [
    "### Classification: Dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "LRD4 = np.zeros((5, 3))\n",
    "KNND4 = np.zeros((5, 3))\n",
    "RDF4 = np.zeros((5, 3))\n",
    "for trial in range(5):\n",
    "    X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, train_size = 5000)\n",
    "    metrics_acc_log, metrics_f1_log, metrics_auc_log, results_log_d4 = log_reg(X4_train, X4_test, y4_train, y4_test)\n",
    "    metrics_acc_knn, metrics_f1_knn, metrics_auc_knn, results_knn_d4 = knn(X4_train, X4_test, y4_train, y4_test)\n",
    "    metrics_acc_rf, metrics_f1_rf, metrics_auc_rf, results_rf_d4 = rand_for(X4_train, X4_test, y4_train, y4_test)\n",
    "    LRD4[trial][0] = metrics_acc_log\n",
    "    LRD4[trial][1] = metrics_f1_log\n",
    "    LRD4[trial][2] = metrics_auc_log\n",
    "    KNND4[trial][0] = metrics_acc_knn\n",
    "    KNND4[trial][1] = metrics_f1_knn\n",
    "    KNND4[trial][2] = metrics_auc_knn\n",
    "    RDF4[trial][0] = metrics_acc_rf\n",
    "    RDF4[trial][1] = metrics_f1_rf\n",
    "    RDF4[trial][2] = metrics_auc_rf\n",
    "LRD4 = pd.DataFrame(LRD4, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "KNND4 = pd.DataFrame(KNND4, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "RDF4 = pd.DataFrame(RDF4, columns=['accuracy', 'f1', 'roc_auc'])\n",
    "\n",
    "AD4 = [[LRD4], [KNND4], [RDF4]]\n",
    "AD4 = pd.DataFrame(AD4, columns = ['MUSH'], index = ['LR', 'KNN', 'RAND_FOR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "LRD4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNND4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-rubber",
   "metadata": {},
   "source": [
    "## Collect Necessary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log_d1 = pd.DataFrame(results_log_d1)\n",
    "results_knn_d1 = pd.DataFrame(results_knn_d1)\n",
    "results_rf_d1 = pd.DataFrame(results_rf_d1)\n",
    "results_log_d2 = pd.DataFrame(results_log_d2)\n",
    "results_knn_d2 = pd.DataFrame(results_knn_d2)\n",
    "results_rf_d2 = pd.DataFrame(results_rf_d2)\n",
    "results_log_d3 = pd.DataFrame(results_log_d3)\n",
    "results_knn_d3 = pd.DataFrame(results_knn_d3)\n",
    "results_rf_d3 = pd.DataFrame(results_rf_d3)\n",
    "results_log_d4 = pd.DataFrame(results_log_d4)\n",
    "results_knn_d4 = pd.DataFrame(results_knn_d4)\n",
    "results_rf_d4 = pd.DataFrame(results_rf_d4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log_d1.to_csv('results/results_log_d1.csv'index=False)\n",
    "results_knn_d1.to_csv('results/results_knn_d1.csv'index=False)\n",
    "results_rf_d1.to_csv('results/results_rf_d1.csv'index=False)\n",
    "results_log_d2.to_csv('results/result_log_d2.csv'index=False)\n",
    "results_knn_d2.to_csv('results/results_knn_d2.csv'index=False)\n",
    "results_rf_d2.to_csv('results/results_rf_d2.csv'index=False)\n",
    "results_log_d3.to_csv('results/results_log_d3.csv'index=False)\n",
    "results_knn_d3.to_csv('results/results_knn_d3.csv'index=False)\n",
    "results_rf_d3.to_csv('results/results_rf_d3.csv'index=False)\n",
    "results_log_d4.to_csv('results/results_log_d4.csv'index=False)\n",
    "results_knn_d4.to_csv('results/results_knn_d4.csv'index=False)\n",
    "results_rf_d4.to_csv('results/results_rf_d4.csv'index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-masters",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-newton",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = [AD1, AD2, AD3, AD4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example\n",
    "results[1]['COVTYPE']['KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['LR', 'KNN', 'RAND_FOR']\n",
    "datasets = ['ADULT', 'COVTYPE', 'LETTER', 'MUSH']\n",
    "metrics = ['accuracy', 'f1', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics each algo/data combo averaged across 5 trials (algorithms in rows, data sets in columns)\n",
    "results1 = np.zeros((3, 4))\n",
    "for col, data in enumerate(datasets):\n",
    "    for row, algo in enumerate(algorithms):\n",
    "        sums = [sum_ for sum_ in results[col][data][algo].sum()]\n",
    "        avg = sum(sums)/15\n",
    "        results1[row][col] = avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = pd.DataFrame(results1, columns = datasets, index = algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy, FSC, and AUC averaged across all data sets (algorithms in rows, metrics in columns)\n",
    "acc = 0\n",
    "f1 = 0\n",
    "roc = 0\n",
    "results2 = np.zeros((3, 3))\n",
    "\n",
    "for row, algo in enumerate(algorithms):\n",
    "    for i, data in enumerate(datasets):\n",
    "        sums = [sum_ for sum_ in results[i][data][algo].sum()]\n",
    "        acc += sums[0]\n",
    "        f1 += sums[1]\n",
    "        roc += sums[2]\n",
    "    results2[row][0] = acc/20\n",
    "    results2[row][1] = f1/20\n",
    "    results2[row][2] = roc/20\n",
    "    acc = 0\n",
    "    f1 = 0\n",
    "    roc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.DataFrame(results2, columns = metrics, index = algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results2.sum(axis=1)\n",
    "sum_metrics = [sum_/3 for sum_ in results2.sum(axis=1)]\n",
    "results2['avg'] = sum_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1.to_csv('tables/results_over_datasets'index=False)\n",
    "results2.to_csv('tables/results_over_metrics'index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
